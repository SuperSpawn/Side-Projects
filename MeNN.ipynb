{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuperSpawn/Side-Projects/blob/main/MeNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actions = ['eat', 'sleep', 'meet someone new', 'drink water']"
      ],
      "metadata": {
        "id": "AqtHSuxsTmnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the network\n",
        "class MeNN(nn.Module):\n",
        "    def __init__(self, activation, input_size, third_size, output_size):\n",
        "        super(MeNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, third_size)\n",
        "        self.activation = activation\n",
        "        # self.fc2 = nn.Linear(second_size, third_size)\n",
        "        self.fc3 = nn.Linear(third_size, output_size)\n",
        "        self.double()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        # x = self.fc2(x)\n",
        "        # x = self.activation(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ORACn7apVa2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def save_dataset(output_file, data):\n",
        "  with open(output_file, \"w\", newline=\"\") as csvfile:\n",
        "    # Create a CSV writer object\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=[\"input\", \"output\"])\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write each data point as a row in the CSV file\n",
        "    for item in data:\n",
        "        writer.writerow(item)\n",
        "\n"
      ],
      "metadata": {
        "id": "huKhUqSGqPA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data\n",
        "\n",
        "# Generate data\n",
        "# save it to a file\n",
        "# load file for training\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def generate_instance(ranges):\n",
        "  instance = []\n",
        "  for inp in ranges:\n",
        "    val = random.uniform(inp[0], inp[1])\n",
        "    instance.append(val)\n",
        "  return instance\n",
        "\n",
        "def generate_dataset_case(input_ranges, output_ranges, size):\n",
        "    dataset = []\n",
        "    for _ in range(size):\n",
        "      data = []\n",
        "      data.append(generate_instance(input_ranges))\n",
        "      data.append(generate_instance(output_ranges))\n",
        "      dataset.append(data)\n",
        "    return dataset\n",
        "\n",
        "def generate_dataset(size, flags, case_size):\n",
        "  total_data = []\n",
        "  for i in range(size):\n",
        "    input_ranges = np.full((size, 2), (0.5, 0.5))\n",
        "    output_ranges = np.full((size, 2), (0.5, 0.5))\n",
        "\n",
        "    input_ranges_low = input_ranges.copy()\n",
        "    input_ranges_high = input_ranges.copy()\n",
        "    output_ranges_low = output_ranges.copy()\n",
        "    output_ranges_high = output_ranges.copy()\n",
        "\n",
        "    input_ranges_low[i] = (0.0, 0.5)\n",
        "    input_ranges_high[i] = (0.5, 1.0)\n",
        "\n",
        "    output_ranges_low[i] = (0.0, 0.5)\n",
        "    output_ranges_high[i] = (0.5, 1.0)\n",
        "\n",
        "    if flags[i]['reverse']:\n",
        "      temp = output_ranges_low\n",
        "      output_ranges_low = output_ranges_high\n",
        "      output_ranges_high = temp\n",
        "\n",
        "    dataset_case_low = generate_dataset_case(input_ranges_low, output_ranges_low, case_size)\n",
        "    dataset_case_high = generate_dataset_case(input_ranges_high, output_ranges_high, case_size)\n",
        "\n",
        "    dataset_case = [i for i in dataset_case_low] + dataset_case_high\n",
        "\n",
        "    total_data = [i for i in dataset_case] + total_data\n",
        "  return total_data\n",
        "\n",
        "\n",
        "# print(dataset)\n",
        "# save_dataset('test.csv', dataset)"
      ],
      "metadata": {
        "id": "Z1wax4Jci9VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = generate_dataset(4, [{'reverse': False}, {'reverse': False}, {'reverse': True}, {'reverse': False}], 4000)\n",
        "print(len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-otVECyba6hQ",
        "outputId": "8026bb00-9cd0-4015-856f-a4838a8d6202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "class MeNNDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = np.array(data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return a single data point and its label\n",
        "        return self.data[idx]\n",
        "\n"
      ],
      "metadata": {
        "id": "tzIENdR8ndkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets and data loaders\n",
        "train_dataset = MeNNDataset(dataset)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# test_dataset = MeNNDataset(\"test.csv\")\n",
        "# test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "ugWwUNeyjcVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_loader:\n",
        "  print(data[0])"
      ],
      "metadata": {
        "id": "cLTdFLlzqaTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model, loss function, and optimizer\n",
        "model = MeNN(nn.ReLU(), 4, 4, 4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(40):\n",
        "    # Train on each batch\n",
        "    for data in train_loader:\n",
        "        for i in data:\n",
        "          # Forward pass\n",
        "          output = model(i[0])\n",
        "\n",
        "          # Calculate loss\n",
        "          loss = criterion(output, i[1])\n",
        "\n",
        "          # Backward pass and update parameters\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()"
      ],
      "metadata": {
        "id": "RoBt5wfnnBVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model.eval()\n",
        "\n",
        "# Convert the input to a PyTorch tensor\n",
        "input_tensor = torch.tensor([0.1, 0.0, 0.8, 0.9], dtype=torch.float64)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model(input_tensor)\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "\n",
        "_, topk_indices = torch.topk(prediction, k=1)\n",
        "action = topk_indices[0]\n",
        "print(actions[action])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z13G7wSno6R",
        "outputId": "d5ffdda4-dfef-4046-c10a-60b5e845730d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.5386, -0.3085,  0.1372,  0.7362], dtype=torch.float64,\n",
            "       grad_fn=<ViewBackward0>)\n",
            "drink water\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = generate_dataset(4, [{'reverse': False}, {'reverse': False}, {'reverse': True}, {'reverse': False}], 100)\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VWarEvErRiK",
        "outputId": "c0cf8798-25a7-456d-8dc3-30c54b5e3228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hit = 0\n",
        "total = 0\n",
        "for data in test_data:\n",
        "  input_tensor = torch.tensor(data[0], dtype=torch.float64)\n",
        "  prediction = model(input_tensor) # input\n",
        "\n",
        "  _, topk_indices = torch.topk(prediction, k=1)\n",
        "  prediction_index = topk_indices[0]\n",
        "\n",
        "  max_value = max(data[1])\n",
        "  max_index = data[1].index(max_value)\n",
        "\n",
        "  if max_index == prediction_index:\n",
        "    hit+=1\n",
        "  total+=1\n",
        "\n",
        "print(f\"Accuracy: %{100 * hit/total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVO4uxyGXeUx",
        "outputId": "ec0d73b4-5ab8-44eb-c996-d1a60612a90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: %84.875\n"
          ]
        }
      ]
    }
  ]
}